# -*- coding: utf-8 -*-
"""graph_measures.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JKD7aqiSI_qGffTB7EDzcy0qtT96MfB_
"""

'''
Jo√£o Vitor B. S. Merenda
Let's take some measures of the networks
'''
import networkx as nx
import numpy as np
import math
from scipy.stats import linregress
import os

#Measures
def measures(G):
  N = G.number_of_nodes() #Number of nodes
  M = G.number_of_edges() #Number of edges
  density = nx.density(G) #Densidade
  #Average degree
  degree = [deg for _, deg in G.degree()]
  avg_degree = np.mean(degree)
  std_degree = np.std(degree)

  clustering_global = nx.transitivity(G) #Global Clustering
  #Average shortest paths and diameter
  if(nx.is_connected(G)):
    average_shortest_path = nx.average_shortest_path_length(G)
    diameter = nx.diameter(G) #diameter
  else:
    bigger_component = max(nx.connected_components(G), key=len)
    G_bigger_component = G.subgraph(bigger_component).copy()
    average_shortest_path = nx.average_shortest_path_length(G_bigger_component)
    diameter = nx.diameter(G_bigger_component) #diameter


  #Power law exponent
  degree_count = np.array(np.unique(degree, return_counts=True)).T
  log_degree = np.log(degree_count[:, 0])
  log_freq = np.log(degree_count[:, 1])
  gamma, _, _, _, _ = linregress(log_degree, log_freq)

  #Small-worldness omega coefficient
  random_graph = nx.erdos_renyi_graph(N, density)
  random_clustering = nx.transitivity(random_graph)
  if(nx.is_connected(random_graph)):
    average_shortest_path_random = nx.average_shortest_path_length(random_graph)
  else:
    bigger_component_random = max(nx.connected_components(random_graph), key=len)
    G_bigger_component_random = random_graph.subgraph(bigger_component_random).copy()
    average_shortest_path_random = nx.average_shortest_path_length(G_bigger_component_random)
  omega = (average_shortest_path_random / average_shortest_path) - (clustering_global / random_clustering)

  return N, M, density, avg_degree, std_degree, clustering_global, average_shortest_path, diameter, gamma, omega


#Infering the probability of connection by two methods. The edge counting method, and the average degree method.


def infer_p_edges(G):
    n = G.number_of_nodes()  # Number of nodes
    E = G.number_of_edges()  # Number of edges
    # p estimate
    p = (2 * E) / (n * (n - 1))
    return p

def infer_p_avgdegree(G):
    n = G.number_of_nodes()  # Number of nodes
    k_medio = sum(dict(G.degree()).values()) / n  # average degree
    # p estimate
    p = k_medio / (n - 1)
    return p


#creating a pandas dataframe
def dataframe(G, file_name):
  import pandas as pd
  N, M, density, avg_degree, std_degree, clustering_global, average_shortest_path, diameter, gamma, omega = measures(G)
  p_edges = infer_p_edges(G)
  p_avgdegree = infer_p_avgdegree(G)
  medidas = {
    "Network name": [file_name],
    "Number of nodes": [N],
    "Number of edges": [M],
    "Density": [density],
    "Average Degree": [avg_degree],
    "Standarddeviation degree": [std_degree],
    "Transitivity": [clustering_global],
    "Average Shortest Path": [average_shortest_path],
    "Diameter": [diameter],
    "Power law exponent": [gamma],
    "small-worldness coefficient": [omega],
    "p method 1": [p_edges],
    "p method 2": [p_avgdegree]
  }
  df = pd.DataFrame(medidas)
  return df


directory = '/home/DATA/datasets/SIS_teps/networks/train_nets/'
output_directory = '/home/DATA/datasets/SIS_teps/networks/results/'
files = sorted([f for f in os.listdir(directory) if f.startswith('tep')])
for arquivo in files:
  G = nx.read_gml(directory + arquivo)
  file_name = arquivo.replace('.gml', '')
  df = dataframe(G, file_name)
  df.to_csv("net_measures.csv", index=False)